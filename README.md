# ğŸ•·ï¸ ScrapJaune - Scraper PagesJaunes avec MongoDB

Un systÃ¨me complet de scraping pour PagesJaunes.fr avec stockage automatique en collections MongoDB organisÃ©es par type d'Ã©tablissement.

## ğŸ“‹ FonctionnalitÃ©s

- âœ… Scraping automatisÃ© des pages PagesJaunes.fr
- âœ… Extraction complÃ¨te des donnÃ©es d'Ã©tablissements
- âœ… Gestion de la pagination automatique
- âœ… **Collections automatiques par type** : Restaurants, Coiffeurs, Dentistes, etc.
- âœ… **CrÃ©ation automatique** de nouvelles collections pour nouveaux types
- âœ… Gestion des doublons intelligente
- âœ… Interface de menu intuitive
- âœ… Logs dÃ©taillÃ©s

## ğŸ¯ DonnÃ©es extraites

Pour chaque Ã©tablissement :

- **Nom** de l'Ã©tablissement
- **Type/ActivitÃ©** (restaurant, coiffeur, etc.)
- **Adresse** complÃ¨te
- **Certification professionnelle** (oui/non)
- **Avis clients** (note + commentaire)
- **Horaires** d'ouverture
- **MÃ©tadonnÃ©es** (note moyenne, nombre d'avis, etc.)

## ğŸ—ƒï¸ Organisation MongoDB

### Collections automatiques par type

Le systÃ¨me crÃ©e automatiquement une collection pour chaque type d'Ã©tablissement :

```
pagesjaunes_db/
â”œâ”€â”€ restaurant/          # Collection des restaurants
â”œâ”€â”€ coiffeur/           # Collection des coiffeurs
â”œâ”€â”€ dentiste/           # Collection des dentistes
â”œâ”€â”€ boulangerie/        # Collection des boulangeries
â””â”€â”€ ...                 # Autres types dÃ©couverts automatiquement
```

### Noms de collections automatiques

Les types sont automatiquement nettoyÃ©s pour crÃ©er des noms valides :

| Type original           | Collection MongoDB    |
| ----------------------- | --------------------- |
| "Restaurant"            | `restaurant`          |
| "Coiffeur / Barbier"    | `coiffeur_barbier`    |
| "Dentiste - Chirurgien" | `dentiste_chirurgien` |
| "Auto-Ã‰cole"            | `auto_ecole`          |

### Avantages de cette organisation

âœ… **Organisation claire** : Chaque secteur dans sa propre collection
âœ… **Performances optimales** : RequÃªtes plus rapides par type
âœ… **Ã‰volutivitÃ©** : Nouveaux types = nouvelles collections automatiques
âœ… **Analyses sectorielles** : Statistiques par type d'activitÃ©
âœ… **Index spÃ©cialisÃ©s** : Optimisation par secteur

## ğŸ› ï¸ Installation

### PrÃ©requis

1. **Python 3.7+**
2. **Google Chrome** (pour Selenium)
3. **MongoDB** (local ou distant)

### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

### Configuration Chrome

Assurez-vous que ChromeDriver est installÃ© ou utilisez la gestion automatique de Selenium.

## ğŸš€ Utilisation

### Lancement du menu principal

```bash
cd ScrapJaune
python main.py
```

### Menu interactif

```
ğŸ•·ï¸  SCRAPER PAGESJAUNES + MONGODB
============================================================
1. ğŸš€ Scraping complet (scraping + stockage MongoDB)
2. ğŸ“¥ Stocker un fichier JSON existant en MongoDB
3. ğŸ“‹ Lister les fichiers de rÃ©sultats
4. ğŸ”§ Scraping uniquement (sans stockage)
5. âŒ Quitter
============================================================
ğŸ’¾ Mode: Collections par type d'Ã©tablissement
============================================================
```

### Options disponibles

1. **Scraping complet** : Lance le scraping ET stocke automatiquement en MongoDB
2. **Stockage fichier existant** : Importe un fichier JSON dÃ©jÃ  gÃ©nÃ©rÃ© en MongoDB
3. **Lister fichiers** : Affiche tous les fichiers de rÃ©sultats disponibles
4. **Scraping seul** : Lance seulement le scraping (gÃ©nÃ¨re un fichier JSON)

## ğŸ“ Structure du projet

```
ScrapJaune/
â”œâ”€â”€ main.py                                    # Script principal avec menu
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â””â”€â”€ pagesjaunes_simple_module.py      # Module de scraping
â”‚   â””â”€â”€ storage/
â”‚       â””â”€â”€ mongodb_storage.py                # Module de stockage MongoDB
â”œâ”€â”€ resultats/                                 # Fichiers JSON gÃ©nÃ©rÃ©s
â”œâ”€â”€ scraping.log                              # Logs d'exÃ©cution
â”œâ”€â”€ requirements.txt                          # DÃ©pendances
â””â”€â”€ README.md                                 # Documentation
```

## ğŸ—ƒï¸ Structure des donnÃ©es MongoDB

### Document type dans une collection

```javascript
{
  "name": "Restaurant Le Gourmet",
  "professional": true,
  "type": "Restaurant",
  "address": "123 Rue de la Paix, 75001 Paris",
  "avis": [...],
  "horaires": {
    "Lundi": "09:00-12:00 / 14:00-22:00",
    "Mardi": "09:00-12:00 / 14:00-22:00",
    "Dimanche": "FermÃ©"
  },
  "metadata": {
    "hash_id": "abc123...",
    "inserted_at": "2024-01-15T10:30:00Z",
    "note_moyenne": 4.5,
    "nombre_avis": 2,
    "source": "pagesjaunes_scraper"
  },
  "searchable_name": "restaurant le gourmet",
  "has_reviews": true,
  "has_schedule": true
}
```

## âš™ï¸ Configuration

### MongoDB

Par dÃ©faut, le systÃ¨me se connecte Ã  :

- **Host** : localhost
- **Port** : 27017
- **Base** : pagesjaunes_db
- **Mode** : Collections par type

### Modifier la configuration

Dans `main.py` :

```python
manager = ScrapingManager(
    mongo_host="votre_host",
    mongo_port=27017
)
```

## ğŸ“Š FonctionnalitÃ©s avancÃ©es

### Gestion automatique des collections

- **DÃ©tection automatique** : Nouveau type = nouvelle collection
- **Nettoyage des noms** : CaractÃ¨res spÃ©ciaux gÃ©rÃ©s automatiquement
- **Index automatiques** : Chaque collection a ses propres index
- **Statistiques par type** : MÃ©triques dÃ©taillÃ©es par secteur

### Gestion des doublons

Le systÃ¨me utilise un hash basÃ© sur le nom + adresse pour Ã©viter les doublons :

- **Nouvel Ã©tablissement** â†’ Insertion
- **Ã‰tablissement existant** â†’ Mise Ã  jour
- **DonnÃ©es identiques** â†’ IgnorÃ©

### Index MongoDB automatiques

**Pour chaque collection :**

- Index textuel sur nom + type
- Index sur l'adresse
- Index sur les notes et avis
- Index unique sur le hash_id
- Index sur le statut professionnel
- Index sur la date d'insertion

### Statistiques dÃ©taillÃ©es

```
=== STATISTIQUES GLOBALES ===
total_establishments: 156
average_rating: 4.2
collections_count: 8

=== DÃ‰TAILS PAR TYPE ===
restaurant: 45 Ã©tablissements, note moyenne: 4.3
coiffeur: 32 Ã©tablissements, note moyenne: 4.1
dentiste: 28 Ã©tablissements, note moyenne: 4.5
...
```

## ğŸ”§ Utilisation programmatique

### Scraping complet

```python
from main import ScrapingManager

manager = ScrapingManager()
stats = manager.demarrer_scraping_complet("restaurant", "Paris")
```

### Stockage seul

```python
from src.storage.mongodb_storage import load_and_store_data

success = load_and_store_data("resultats/mon_fichier.json")
```

### AccÃ¨s direct aux collections

```python
from pymongo import MongoClient

client = MongoClient("localhost", 27017)
db = client.pagesjaunes_db

# AccÃ¨s par type
restaurants = db.restaurant.find({"professional": True})
coiffeurs = db.coiffeur.find({"metadata.note_moyenne": {"$gte": 4.0}})
dentistes = db.dentiste.find({"has_reviews": True})
```

### RequÃªtes utiles

```python
# Top 10 des restaurants les mieux notÃ©s
top_restaurants = db.restaurant.find().sort("metadata.note_moyenne", -1).limit(10)

# Coiffeurs professionnels Ã  Paris
coiffeurs_paris = db.coiffeur.find({
    "professional": True,
    "address": {"$regex": "Paris", "$options": "i"}
})

# Dentistes avec horaires d'ouverture
dentistes_ouverts = db.dentiste.find({"has_schedule": True})
```

## ğŸ“ Logs

Les logs sont sauvegardÃ©s dans `scraping.log` et affichÃ©s en temps rÃ©el.

Informations trackÃ©es :

- **Collections crÃ©Ã©es** : Notification lors de crÃ©ation automatique
- **Types dÃ©couverts** : Liste des collections crÃ©Ã©es
- **Statistiques par type** : DÃ©tails par secteur d'activitÃ©

## âš ï¸ Limitations

- NÃ©cessite une connexion internet stable
- DÃ©pendant de la structure HTML de PagesJaunes
- Peut Ãªtre affectÃ© par les limitations de dÃ©bit
- NÃ©cessite Chrome installÃ©
- **Noms de collections** : Les types trÃ¨s longs sont tronquÃ©s (max 50 caractÃ¨res)

## ğŸ’¡ Exemples d'utilisation

### Analyse par secteur

```python
# Comparer les notes moyennes par secteur
pipeline = [
    {"$group": {
        "_id": "$type",
        "note_moyenne": {"$avg": "$metadata.note_moyenne"},
        "count": {"$sum": 1}
    }},
    {"$sort": {"note_moyenne": -1}}
]

# ExÃ©cuter sur toutes les collections
for collection_name in db.list_collection_names():
    if not collection_name.startswith('system.'):
        result = list(db[collection_name].aggregate(pipeline))
        print(f"{collection_name}: {result}")
```

### Recherche gÃ©ographique

```python
# Tous les Ã©tablissements d'un arrondissement
arr_75001 = []
for collection_name in db.list_collection_names():
    if not collection_name.startswith('system.'):
        results = db[collection_name].find({
            "address": {"$regex": "75001", "$options": "i"}
        })
        arr_75001.extend(list(results))
```

## ğŸ¤ Contribution

Pour contribuer :

1. Fork le projet
2. CrÃ©ez une branche feature
3. Commitez vos changements
4. Pushez vers la branche
5. Ouvrez une Pull Request

## ğŸ“„ Licence

Ce projet est Ã  des fins Ã©ducatives. Respectez les conditions d'utilisation de PagesJaunes.fr.

---

**DÃ©veloppÃ© avec â¤ï¸ en Python**
