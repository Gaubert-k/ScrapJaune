# üï∑Ô∏è ScrapJaune - Scraper PagesJaunes avec MongoDB

Un syst√®me complet de scraping pour PagesJaunes.fr avec stockage automatique en base de donn√©es MongoDB.

## üìã Fonctionnalit√©s

- ‚úÖ Scraping automatis√© des pages PagesJaunes.fr
- ‚úÖ Extraction compl√®te des donn√©es d'√©tablissements
- ‚úÖ Gestion de la pagination automatique
- ‚úÖ Stockage structur√© en MongoDB
- ‚úÖ Gestion des doublons intelligente
- ‚úÖ Interface de menu intuitive
- ‚úÖ Logs d√©taill√©s

## üéØ Donn√©es extraites

Pour chaque √©tablissement :

- **Nom** de l'√©tablissement
- **Type/Activit√©** (restaurant, coiffeur, etc.)
- **Adresse** compl√®te
- **Certification professionnelle** (oui/non)
- **Avis clients** (note + commentaire)
- **Horaires** d'ouverture
- **M√©tadonn√©es** (note moyenne, nombre d'avis, etc.)

## üõ†Ô∏è Installation

### Pr√©requis

1. **Python 3.7+**
2. **Google Chrome** (pour Selenium)
3. **MongoDB** (local ou distant)

### Installation des d√©pendances

```bash
pip install selenium pymongo
```

### Configuration Chrome

Assurez-vous que ChromeDriver est install√© ou utilisez la gestion automatique de Selenium.

## üöÄ Utilisation

### Lancement du menu principal

```bash
cd ScrapJaune
python main.py
```

### Menu interactif

```
üï∑Ô∏è  SCRAPER PAGESJAUNES + MONGODB
============================================================
1. üöÄ Scraping complet (scraping + stockage MongoDB)
2. üì• Stocker un fichier JSON existant en MongoDB
3. üìã Lister les fichiers de r√©sultats
4. üîß Scraping uniquement (sans stockage)
5. ‚ùå Quitter
============================================================
```

### Options disponibles

1. **Scraping complet** : Lance le scraping ET stocke automatiquement en MongoDB
2. **Stockage fichier existant** : Importe un fichier JSON d√©j√† g√©n√©r√© en MongoDB
3. **Lister fichiers** : Affiche tous les fichiers de r√©sultats disponibles
4. **Scraping seul** : Lance seulement le scraping (g√©n√®re un fichier JSON)

## üìÅ Structure du projet

```
ScrapJaune/
‚îú‚îÄ‚îÄ main.py                                    # Script principal avec menu
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ scrapers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pagesjaunes_simple_module.py      # Module de scraping
‚îÇ   ‚îî‚îÄ‚îÄ storage/
‚îÇ       ‚îî‚îÄ‚îÄ mongodb_storage.py                # Module de stockage MongoDB
‚îú‚îÄ‚îÄ resultats/                                 # Fichiers JSON g√©n√©r√©s
‚îú‚îÄ‚îÄ scraping.log                              # Logs d'ex√©cution
‚îî‚îÄ‚îÄ README.md                                 # Documentation
```

## üóÉÔ∏è Structure des donn√©es

### Format JSON g√©n√©r√© par le scraper

```json
[
  {
    "name": "Restaurant Le Gourmet",
    "professional": "true",
    "type": "Restaurant",
    "address": "123 Rue de la Paix, 75001 Paris",
    "avis": [
      ["4/5", "Excellent service et nourriture d√©licieuse"],
      ["5/5", "Je recommande vivement ce restaurant"]
    ],
    "horaire": [
      ["09:00-12:00 / 14:00-22:00 -> Lundi"],
      ["09:00-12:00 / 14:00-22:00 -> Mardi"],
      ["Ferm√© -> Dimanche"]
    ]
  }
]
```

### Structure MongoDB

```javascript
{
  "name": "Restaurant Le Gourmet",
  "professional": true,
  "type": "Restaurant",
  "address": "123 Rue de la Paix, 75001 Paris",
  "avis": [...],
  "horaires": {
    "Lundi": "09:00-12:00 / 14:00-22:00",
    "Mardi": "09:00-12:00 / 14:00-22:00",
    "Dimanche": "Ferm√©"
  },
  "metadata": {
    "hash_id": "abc123...",
    "inserted_at": "2024-01-15T10:30:00Z",
    "note_moyenne": 4.5,
    "nombre_avis": 2,
    "source": "pagesjaunes_scraper"
  },
  "searchable_name": "restaurant le gourmet",
  "has_reviews": true,
  "has_schedule": true
}
```

## ‚öôÔ∏è Configuration

### MongoDB

Par d√©faut, le syst√®me se connecte √† :

- **Host** : localhost
- **Port** : 27017
- **Base** : pagesjaunes_db
- **Collection** : pageJaune

### Modifier la configuration

Dans `main.py` :

```python
manager = ScrapingManager(mongo_host="votre_host", mongo_port=27017)
```

## üìä Fonctionnalit√©s avanc√©es

### Gestion des doublons

Le syst√®me utilise un hash bas√© sur le nom + adresse pour √©viter les doublons :

- **Nouvel √©tablissement** ‚Üí Insertion
- **√âtablissement existant** ‚Üí Mise √† jour
- **Donn√©es identiques** ‚Üí Ignor√©

### Index MongoDB automatiques

- Index textuel sur nom + type
- Index sur l'adresse
- Index sur les notes et avis
- Index unique sur le hash_id
- Index sur le statut professionnel

### Statistiques

Le syst√®me fournit des statistiques compl√®tes :

- Nombre d'√©tablissements trait√©s
- Nouveaux ins√©r√©s vs mis √† jour
- Doublons ignor√©s
- Erreurs rencontr√©es
- Statistiques globales de la collection

## üîß Utilisation programmatique

### Scraping seul

```python
from src.scrapers.pagesjaunes_simple_module import PagesJaunesScraper

scraper = PagesJaunesScraper()
fichier = scraper.executer_scraping("restaurant", "Paris")
print(f"R√©sultats sauv√©s dans : {fichier}")
```

### Stockage seul

```python
from src.storage.mongodb_storage import load_and_store_data

success = load_and_store_data("resultats/mon_fichier.json")
```

### Processus complet

```python
from main import ScrapingManager

manager = ScrapingManager()
stats = manager.demarrer_scraping_complet("coiffeur", "Lyon")
print(stats)
```

## üìù Logs

Les logs sont sauvegard√©s dans `scraping.log` et affich√©s en temps r√©el.

Niveaux de log :

- **INFO** : Progression g√©n√©rale
- **DEBUG** : D√©tails des op√©rations
- **WARNING** : Avertissements non bloquants
- **ERROR** : Erreurs importantes

## ‚ö†Ô∏è Limitations

- N√©cessite une connexion internet stable
- D√©pendant de la structure HTML de PagesJaunes
- Peut √™tre affect√© par les limitations de d√©bit
- N√©cessite Chrome install√©

## ü§ù Contribution

Pour contribuer :

1. Fork le projet
2. Cr√©ez une branche feature
3. Commitez vos changements
4. Pushez vers la branche
5. Ouvrez une Pull Request

## üìÑ Licence

Ce projet est √† des fins √©ducatives. Respectez les conditions d'utilisation de PagesJaunes.fr.

---

**D√©velopp√© avec ‚ù§Ô∏è en Python**
